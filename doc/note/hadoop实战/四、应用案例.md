## 单词计数
## 去重
利用reduce收到(key, list(value))的特性。  处理文件的时候
map(){
    context.write(line, new Text(""));
}
// 直接存入hdfs就好了
reduce(){
     context.write(key, new Text(""));
}

## 排序
reduce收到数据本身就是排序的。 字典序。

具体还会涉及到更多的排序，比如按照出现几率排序，倒叙等等。以后补充
## 单表关联
bin\hadoop fs -copyFromLocal 3.txt /user/root/input/3.txt
Tom Lucy
Tom Jack
Jone Lucy  
这个样子的， 想个策略， 因为reduce会把所有相同key的汇聚成list, 所以呢，咱们这么处理一下。 以chirld为key，发一个然后以parent发一个。 这样reduce得到的值就是一个人的所有的孩子和所有的长辈。 然后再笛卡尔记一下，就会得到所有的孙爷组合了。

## 多表关联
就是两表的，比上面的还要简单一些，不说了。

## Writable类
有各种各样的子类。 比如CompareWritable类， 实现了这个类就能实现自己的Hadoop类型。
Reducer<Text,IntWritable,Text,IntWritable>  三角号里面的这些都是。

## map中间态
SequenceFile   map输出的中间结果就是他们表示的。
MapFile             经过排序且带有索引的SequenceFile.



