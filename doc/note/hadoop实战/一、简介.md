包含：zookeeper, HDFS, MapReduce众多子项目。
开源分布式计算平台。
以HDFS和MapReduce为核心的Hadoop为用户提供了底层透明的分布式基础架构。
HDFS高容错和伸缩性允许部署在低廉的硬件上。
MapReduce分布式模型不了解分布式系统底层细节的情况下开发并行应用程序。

### 功能和作用
 - 数字信息(浏览记录等)的保存和分析
 - 分布式存储HDFS的数据管理能力
 - Mapreduce 处理任务的高效率
### 优势
 - 高可靠性 分布式存储，防止单点，按位处理
 - 高扩展性  以计算机集簇为单位，可以方便的转移存储
 - 高效性      可在节点中动态的移动数据，保证节点间的动态平衡
 - 高容错性  能够自动保持多个副本

### 应用现状
 - 雅虎用来广告和搜索
 - facebook用来做数据分析和机器学习
 - 百度用它来搜索日志的分析和网页数据的挖掘

## Hadoop项目和结构

![](http://git.oschina.net/wzj777/princeWiki/raw/master/pic/hadoop/hadoop-1.png)

 - Core/Common  为其他子项目提供常用工具，主要包含FileSystem,RPC和串行化库。
 - Avro, 数据序列化的工具， 提供数据结构，快速可压缩的二进制格式，远程PRC调用等功能
 - MapReduce,   map映射，reduce化简。 map把输入的键值对映射成一组新的键值对。 reduce把相同key的所有value进行处理。
 - HDFS,  分布式文件系统。  为了：
       故障检测和快速恢复。 多服务器意味着高故障率，因此要能进行故障检测和快速恢复。
       流式数据访问。    适合批处理，不适合用户交互处理，重视数据吞吐量，而不是数据访问的访问速度。
       简化一致性模型， 一般都是一次写入多次夺取，因此一旦文件创建之后一般不能修改。
       通信协议，  客户端和名字节点走客户端协议， 数据节点和名字节点走数据节点协议。

 - Chukwa.  开源数据收集系统，用于监控和分析大型分布式系统的数据。
 - Hive. 使得对hadoop中的数据能够进行结构化的查询。在hadoop之上建立的数据仓库。
 - HBase, 分布式的，面向列的开源数据库。主要用于需要随机访问，实时读写的大数据。
 - Pig. 

## 体系结构
### HDFS的体系结构
    主从模型。  一个NameNode和多个DataNode组成。 NameNode负责管理文件系统的命名空间和客户端对文件的访问操作。 DataNode管理数据。
    很像elasticsearch的感觉。

### MapReduce的体系结构
    由主节点上的JobTracker和集群节点上的TaskTracker共同组成
    主节点调度任务，监控执行情况，重新执行失败的任务。从节点负责执行。

## Hadoop与分布式开发
map(String key, String value):
    // key: document name// value: document contentsfor each word w in value:
        EmitIntermediate(w, “1″);
reduce(String key, Iterator values):
    // key: a word// values: a list of counts
    int result = 0;
    for each v in values:
        result += ParseInt(v);
    Emit(AsString(result));
Map 接收一个输入的key-value，然后输出一个key-value的list.
        比如上面的这个
                {"file_url", "file_content"}  ->  {"word1":1}
                                                          {"word1":1}
                                                          {"word2":1}
        然后reduce的时候就会收到：
                {"word1":["1", "1"]}  然后最后的输出就是{"word1":2}了。
        这个表达更准确一点：
                map(k1,v1) ->list(k2,v2)
             reduce(k2,list(v2)) ->list(v2)
特别适合任务分解到大量小机器并行计算。原理：
数据分布存储
文件分割成block, 每个block有不同的副本在其他机器中。来达到容灾。 NameNode记录文件存在哪些Block，在哪个DataNode上。

分布式并行计算
JobTracker吧任务发给TaskTracker。DataNode即是存储节点也是计算节点。
监控运行或者重做任务。
本地计算
移动计算，优先于移动数据。  哪台机器上存储了数据，就在哪台电脑上进行计算。
任务粒度
一个任务的数据集小于一个block,以让这个任务的数据在一台电脑上。
数据分割
把map的中间结果分成R(tasktracker的个数)份， 通常是hash取模的方式，让一定范围内内key一定由一个reduce任务来处理。
数据合并
减少key-value的数量
Reduce
map的中间结果保存到本地磁盘，然后位置告诉jobtra,jobtra通知reduce任务到哪一个DataNode上去拿结果。可能需要拿多个DataNode上的任务得到最终结果。
任务管道
有R个任务就会有R个结果，通常不需要合并，可能作为其他计算的输入，因此成为了管道。

## Hadoop计算模型 Map-Reduce

## Hadoop数据管理
